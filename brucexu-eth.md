---
timezone: UTC+12
---

# Bruce Xu

**GitHub ID:** brucexu-eth

**Telegram:** @brucexu_eth

## Self-introduction

Learning AI and Web3.

## Notes

<!-- Content_START -->
# 2025-12-05
<!-- DAILY_CHECKIN_2025-12-05_START -->
To download model files to a local directory, you could use

```
huggingface-cli download --local-dir ./Qwen3-8B Qwen/Qwen3-8B
```

## **Thinking & Non-Thinking Mode**

By default, Qwen3 model will think before response. It is also true for the `pipeline()` interface. To switch between thinking and non-thinking mode, two methods can be used

-   Append a final assistant message, containing only `<think>\n\n</think>\n\n`. This method is stateless, meaning it will only work for that single turn. It will also strictly prevent the model from generating thinking content. For example,
    
    ```
    messages = [
        {"role": "user", "content": "Give me a short introduction to large language models."},
        {"role": "assistant", "content": "<think>\n\n</think>\n\n"},
    ]
    messages = generator(messages, max_new_tokens=32768)[0]["generated_text"]
    # print(messages[-1]["content"])
    
    messages.append({"role": "user", "content": "In a single sentence."})
    messages = generator(messages, max_new_tokens=32768)[0]["generated_text"]
    # print(messages[-1]["content"])
    ```
    
-   Add to the user (or the system) message, `/no_think` to disable thinking and `/think` to enable thinking. This method is stateful, meaning the model will follow the most recent instruction in multi-turn conversations.
    
    ```
    messages = [
        {"role": "user", "content": "Give me a short introduction to large language models./no_think"},
    ]
    messages = generator(messages, max_new_tokens=32768)[0]["generated_text"]
    # print(messages[-1]["content"])
    
    messages.append({"role": "user", "content": "In a single sentence./think"})
    messages = generator(messages, max_new_tokens=32768)[0]["generated_text"]
    # print(messages[-1]["content"])
    ```
    

The maximum context length in pre-training for Qwen3 models is 32,768 tokens. It can be extended to 131,072 tokens with RoPE scaling techniques. We have validated the performance with YaRN.

RoPE (Rotary Positional Embedding)  
RoPE is a way of encoding word positions for transformer models.

YaRN (Yet another RoPE extensioN / context extension method)  
YaRN is a **technique for extending context length** of models that use RoPE, while trying to keep performance stable.

Transformers implements static YaRN, which means the scaling factor remains constant regardless of input length, **potentially impacting performance on shorter texts.** We advise adding the `rope_scaling` configuration only when processing long contexts is required. It is also recommended to modify the `factor` as needed. For example, if the typical context length for your application is 65,536 tokens, it would be better to set `factor` as 2.0.

You may find distributed inference with Transformers is not as fast as you would imagine. Transformers with `device_map="auto"` does not apply tensor parallelism, and it only uses one GPU at a time.

* * *

[https://qwen.readthedocs.io/en/latest/run\_locally/llama.cpp.html](https://qwen.readthedocs.io/en/latest/run_locally/llama.cpp.html)

GGUF[\[1\]](https://qwen.readthedocs.io/en/latest/run_locally/llama.cpp.html#gguf) is a file format for storing information needed to run a model, including but not limited to model weights, model hyperparameters, default generation configuration, and tokenizer.

We provide a series of GGUF models in our Hugging Face organization, and to search for what you need you can search the repo names with `-GGUF`.

```
llama-cli -m ./models/Qwen3-8B-Q4_K_M.gguf --jinja --color -ngl 99 --flash-attn auto -sm row
    --temp 0.6 --top-k 20 --top-p 0.95 --min-p 0 -c 40960 -n 32768 --no-context-shift
```
<!-- DAILY_CHECKIN_2025-12-05_END -->

# 2025-12-04
<!-- DAILY_CHECKIN_2025-12-04_START -->


[https://qwen.readthedocs.io/zh-cn/latest/index.html](https://qwen.readthedocs.io/zh-cn/latest/index.html)

```
pip install transformers
pip install torch
```

create a py file and use the example code

```
# Load model directly
from transformers import AutoTokenizer, AutoModelForCausalLM

tokenizer = AutoTokenizer.from_pretrained("Qwen/Qwen3-4B-Thinking-2507")
model = AutoModelForCausalLM.from_pretrained("Qwen/Qwen3-4B-Thinking-2507")
messages = [
    {"role": "user", "content": "Who are you?"},
]
inputs = tokenizer.apply_chat_template(
	messages,
	add_generation_prompt=True,
	tokenize=True,
	return_dict=True,
	return_tensors="pt",
).to(model.device)

outputs = model.generate(**inputs, max_new_tokens=40)
print(tokenizer.decode(outputs[0][inputs["input_ids"].shape[-1]:]))
```

after running this script, it will download model and packages automatically.

Qwen3 æ”¯æŒé…ç½®æ€è€ƒé¢„ç®—ã€‚å…¶å®ç°æ–¹å¼æ˜¯ï¼Œä¸€æ—¦è¾¾åˆ°é¢„ç®—ï¼Œä¾¿ç»“æŸæ€è€ƒè¿‡ç¨‹ï¼Œå¹¶é€šè¿‡æå‰åœæ­¢æç¤ºå¼•å¯¼æ¨¡å‹ç”Ÿæˆâ€œæ€»ç»“â€ã€‚

* * *

Qwen3 is the newest edition of the Qwen language models, featuring balanced model sizes, enhanced capbilities, hybrid thinking modes, and more language support:

-   With 119 languages (and dialects), Qwen3â€™s extensive multilingual capability opens up new possibilities for international applications.
    
-   Qwen3 models are optimized for coding and agentic capabilities, with strengthened support of Model Context Protocol (MCP) as well.
    

## **Naming**

Starting with Qwen3, the models are named using the scheme `Qwen3[-size][-type][-date]`:

-   `size`: the notation of the structure and the parameter counts. Dense models use the total saved parameters, e.g., `4B` and `32B`, while MoE models use the total saved parameters and the activated parameters for each token with a prepended `A`, e.g., `30B-A3B` and `235B-A22B`.
    
-   `type`: there are currently 4 types:
    
    -   `-Instruct`: the instruction following models that follow the predefined chat template, used for conducting tasks in conversations, downstream fine-tuning, etc.
        
    -   `-Thinking`: the thinking models that follow the predefined chat template and use chain-of-thoughts (CoT) to think deeply about the questions, used for solving complex problems.
        
    -   `-Base`: the pre-trained models that do not know the predefined chat template, used for in-context learning, downstream fine-tuning, etc.
        
    -   No type: the models with hybrid thinking modes.
        
-   `date`: the released date in yearmonth format, e.g., `2507`.
    

Tokens represent the fundamental units that models process and generate. They can represent texts in human languages (regular tokens) or **represent specific functionality like keywords in programming languages** (control tokens [\[1\]](https://qwen.readthedocs.io/en/latest/getting_started/concepts.html#special)).

cool, tokenizer varies based on the task, like for code, will use keywords, this makes sense!

## **Chat Template**

Chat templates provide a structured format for conversational interactions, where predefined placeholders or prompts are used to elicit responses from the model that adhere to a desired dialogue flow or context.

The following is a full example:

```
<|im_start|>system
You are a cat.<|im_end|>
<|im_start|>user
hello<|im_end|>
<|im_start|>assistant
*Meow~* Hello there! The sun is shining so brightly today, and I'm feeling extra fluffy. Did you bring me a treat? ğŸ¾<|im_end|>
<|im_start|>user
Explain large language models like I'm 5.<|im_end|>
<|im_start|>assistant
*Paws at a toy, then looks up with curious eyes*  

Hey there! ğŸ¾ Imagine you have a super-smart robot friend who loves to talk and play. This robot has *gigantic* brainpower (like a million puzzle pieces all stuck together!) and knows *everything* about stories, animals, and even how to make up new words.  

When you ask it a question, like â€œWhatâ€™s a rainbow?â€ it uses its brain to find the answer and then *tells you* it in a way that makes sense. It can even help you write a story or solve a puzzle!  

But hereâ€™s the magic: itâ€™s not just a robotâ€”itâ€™s like a *super-duper* smart helper that learns more every day. Itâ€™s like having a friend whoâ€™s always curious and wants to help you explore the world! ğŸŒŸ  

*Meow~* Want to ask it something fun? ğŸ˜º<|im_end|><|endoftext|>
```

### **Thinking**

Qwen3 supports thinking mode and uses a structured format for thinking content, which uses the `<think>` and `</think>` tokens to separate the thinking content from the regular response. The template for the final round is as follows:

```
<|im_start|>user
{{user content}}<|im_end|>
<|im_start|>assistant
<think>
{{thinking content}}
</think>

{{assistant content}}<|im_end|>
```

[https://qwen.readthedocs.io/en/latest/inference/transformers.html](https://qwen.readthedocs.io/en/latest/inference/transformers.html)

# **Transformers**

Transformers is a library of pretrained natural language processing for inference and training. Developers can use Transformers to train models on their data, build inference applications, and generate texts with large language models.
<!-- DAILY_CHECKIN_2025-12-04_END -->

# 2025-12-03
<!-- DAILY_CHECKIN_2025-12-03_START -->



ä»Šå¤©ä¸»è¦çœ‹äº†ä¸€ä¸‹ [https://www.zetachain.com/docs/developers/tutorials/swap](https://www.zetachain.com/docs/developers/tutorials/swap) è¿™ä¸ªèµ„æ–™
<!-- DAILY_CHECKIN_2025-12-03_END -->

# 2025-12-02
<!-- DAILY_CHECKIN_2025-12-02_START -->




ä»Šå¤©ä¸»è¦çœ‹ Qwen AI ç›¸å…³çš„å†…å®¹ã€‚

æ„Ÿè§‰ Qwen å¾ˆå¼ºå¤§ï¼Œæœªæ¥è¿˜æ˜¯æŒºå‰å®³çš„ã€‚æœ‰å‰æ™¯ã€‚
<!-- DAILY_CHECKIN_2025-12-02_END -->

# 2025-11-29
<!-- DAILY_CHECKIN_2025-11-29_START -->






[https://www.zetachain.com/docs/developers/evm](https://www.zetachain.com/docs/developers/evm)

ZetaChain uses a hub-and-spoke architecture:

-   Hub: ZetaChain, the main coordination layer for all cross-chain activity.
    
-   Spokes: External blockchains (EVM, Solana, Sui, Ton, and Bitcoin) connected with standardized protocols.
    

All cross-chain messages and transactions pass through ZetaChain, ensuring consistent handling, easier integration of new chains, and a single point for enforcing security and validation rules.

**Observer-Signer Validators**

-   Monitor ZetaChain and connected chains for cross-chain events.
    
-   Vote on event validity; upon majority agreement, coordinate outbound transactions.
    
-   Sign outbound transactions using a Threshold Signature Scheme (TSS) so no single validator controls the signing key.
    

* * *

ZetaChain is used as a ledger for cross chain events.

## [**Protocol Contracts**](https://www.zetachain.com/docs/developers/evm#protocol-contracts)

To enable interaction between users, applications, and the ZetaChain network, protocol contracts are deployed both on ZetaChain and on connected external chains.

**On ZetaChain**

| Contract | Purpose |
| --- | --- |
| GatewayZEVM | Primary entry point for outbound transactions. Handles asset withdrawals, external contract calls, and ZRC-20 mint/burn logic. |
| ZRC-20 | ERC-20â€“compliant tokens representing assets from connected chains, enabling fungible asset transfers within ZetaChain. |
| ContractRegistry | Stores and provides metadata for deployed protocol contracts (e.g., gateway, ZRC-20s) to ensure consistent references across the network. |

**On Connected EVM Chains**

| Contract | Purpose |
| --- | --- |
| GatewayEVM | Entry point for inbound transactions. Handles deposits, contract calls to ZetaChain, and emits events for observers to track. |
| ERC20Custody | Holds ERC-20 assets deposited for cross-chain transfers, ensuring secure custody until transactions are processed. |
| ContractRegistry | Stores and provides metadata for deployed protocol contracts on the connected chain, allowing clients and services to locate the correct contract addresses. |

**On Other Connected Chains (Solana, Sui, TON, etc.)**

| Contract | Purpose |
| --- | --- |
| Gateway | Entry point for initiating and receiving cross-chain transactions between the connected chain and ZetaChain. Functions are adapted to the chainâ€™s native runtime (e.g., Solana program, Sui Move module, TON smart contract). |

## [**Cross-Chain Transaction Workflow**](https://www.zetachain.com/docs/developers/evm#cross-chain-transaction-workflow)

The process differs for **incoming** (connected chain â†’ ZetaChain) and **outgoing** (ZetaChain â†’ connected chain) transactions, but both follow a secure, validator-driven workflow.

ZetaChain removes much of the friction of building cross-chain applications. Instead of juggling different SDKs, bridges, and security models, you get a single platform that handles cross-chain messaging, asset movement, and contract calls for you.

TODO make a cross chain tx to have a try on mainnet and Sol

[https://www.zetachain.com/docs/developers/evm/gateway](https://www.zetachain.com/docs/developers/evm/gateway)

![image.png](https://raw.githubusercontent.com/IntensiveCoLearning/Universal-AI/main/assets/brucexu-eth/images/2025-11-29-1764381138415-image.png)

[https://www.zetachain.com/docs/developers/evm/gas](https://www.zetachain.com/docs/developers/evm/gas)

TODO Ethereumâ€™s EIP 1559 fee model

## [**Outgoing Calls and Withdrawals**](https://www.zetachain.com/docs/developers/evm/gas#outgoing-calls-and-withdrawals)

Universal apps on ZetaChain can initiate calls to contracts on connected chains or facilitate withdrawals of ZRC-20 tokens back to a connected chain. These operations require a â€œwithdraw gas fee,â€ which is calculated based on the gas limit of the target chain.

Itâ€™s important to query the current gas fee, approve the Gateway to spend the necessary amount, and ensure the gas ZRC-20 token balance is sufficient. If the Gateway cannot transfer the required fee to itself, the operation will fail.

ZRC-20 token refers to the outgoing chainâ€™s ZRC-20 tokens, so you need to estimate the gas first, then submit the tx. ZetaChain will help you to send TXs with same (or similar) gas settings to make it work. In this way, the gas token will be deducted from ZetaChain directly. ZetaChain can even get some tips if they want to. Similar to CEX withdrawal.

| Chain ID | ZRC-20 | Fee Amount | Fee Token |
| --- | --- | --- | --- |
| 1 | USDC.ETH | 0.0000222162735 | ETH.ETH |
| 1 | PEPE.ETH | 0.0000222162735 | ETH.ETH |

To calculate fees for a different gas limit, please, check out use the `query fees` command:

```
npx zetachain query fees
```

[https://www.zetachain.com/docs/developers/evm/cctx](https://www.zetachain.com/docs/developers/evm/cctx)

Cross-chain transactions (CCTXs) can be classified into two main types: incoming and outgoing.

**Incoming transactions** (connected chain â†’ ZetaChain) are initiated on a connected chain and result in a transaction on ZetaChain. An incoming transaction consists of two transactions:

-   Inbound: a transaction is initiated and observed on the connected chain.
    
-   Outbound: the corresponding transaction is broadcasted and executed on ZetaChain.
    

**Outgoing transactions** (ZetaChain â†’ connected chain) are initiated on ZetaChain and result in a transaction on a connected chain. An outgoing transaction consists of two transactions:

-   Inbound: A transaction is initiated and observed on ZetaChain.
    
-   Outbound: The corresponding transaction is broadcasted and executed on the connected chain.
    

Tracking a CCTX involves querying ZetaChainâ€™s Cosmos SDK HTTP API with an inbound transaction hash to get a CCTX hash.

TODO intents on ZetaChain?

TODO What will happen if ZetaChain doesnâ€™t have enough token on the connected outgoing chain? For example, if I want to swap 1eth from mainnet to BNB on BSC, but on ZetaChain contract on BSC, only 1BNB left. What will happen?

## What is Threshold Signature Scheme?

In a _t-of-n_ TSS, the private key is divided into _n_ unique shares (held by different parties) and at least _t_ of those parties must collaborate to sign a transaction. This approach is designed to eliminate the single point of failure inherent in traditional single-key wallets: no single person holds the entire private key, so compromising one share does not compromise the whole key

TSS has emerged as a solution in blockchain systems to enhance security and trust. By distributing key control among multiple parties, TSS ensures that **â€œthe key never existsâ€** in one place
<!-- DAILY_CHECKIN_2025-11-29_END -->

# 2025-11-28
<!-- DAILY_CHECKIN_2025-11-28_START -->








[https://www.zetachain.com/docs/start/app](https://www.zetachain.com/docs/start/app)

![image.png](https://raw.githubusercontent.com/IntensiveCoLearning/Universal-AI/main/assets/brucexu-eth/images/2025-11-27-1764275585407-image.png)

ZetaChain is like a bridge.

In this example a universal app:

-   accepts 6 ETH and "I want BNB" (bytes that represent the destination token) from Ethereum
    
-   swaps 6 ZRC-20 ETH for ZRC-20 BNB using a decentralized exchange on ZetaChain
    
-   calls the Gateway contract to withdraw ZRC-20 BNB and call a contract on the BNB chain
    

Of course, a single universal app call can trigger more than one call to different chains.

DeFi and Oracle is very important.

TODO implement a demo to use ETH buy BTC on BTC.

* * *

Incoming call to universal apps do not incur additional gas costs. But outgoing calls from universal apps require gas, need to deposit ZRC-20 gas token.

In practice it means that a universal app would swap a fraction of the incoming ZRC-20 token to the ZRC-20 of the gas token of the chain to which an outgoing call is made. When an outgoing call or withdrawal is made, a required amount of ZRC-20 gas token is deducted to cover the gas fees on the destination chain.

TODO how ZRC-20 and gas fee calculated? if the token price is uncertain?

* * *

[https://www.zetachain.com/docs/start/build](https://www.zetachain.com/docs/start/build)

One of the core capabilities of universal apps on ZetaChain is the ability to transfer value using native tokens across all connected chains. This means users can perform transactions involving the actual native assets of each blockchain, rather than wrapped or synthetic versions.

ZetaChain runs smart contracts on its Universal Ethereum Virtual Machine (UEVM), which is fully compatible with Ethereum's EVM.

Another compelling feature of ZetaChain is its Gasless EVM Execution Environment. Universal apps run on ZetaChain's EVM and can be called by users and contracts from all connected chains. When a universal app is called from a connected chain, it requires gas payment only on that connected chain.

Execution on ZetaChain does not impose any additional fees, making ZetaChain a cost-effective, gasless environment for deploying contracts.

TODO how ZetaChain make profits?

* * *

[https://www.zetachain.com/docs/developers/architecture/overview](https://www.zetachain.com/docs/developers/architecture/overview)

At a high level, ZetaChain is a Proof of Stake (PoS) blockchain built on the Cosmos SDK and Comet BFT consensus engine.

TODO check Cosmos [https://github.com/cosmos/cosmos-sdk](https://github.com/cosmos/cosmos-sdk)

Contained within each validator is the ZetaCore and ZetaClient. ZetaCore is responsible for producing the blockchain and maintaining the replicated state machine. ZetaClient is responsible for observing events on connected chains and signing outbound transactions.

Validators are comprised of 2 different roles: Core Validators and Observer-Signer Validators. Fees from transactions and rewards are distributed to validators in return for their service of processing transactions and keeping the network secure.
<!-- DAILY_CHECKIN_2025-11-28_END -->

# 2025-11-27
<!-- DAILY_CHECKIN_2025-11-27_START -->









Created a new education tool for anaylzing solidity [https://github.com/brucexu-eth/evm-runtime-visualizer](https://github.com/brucexu-eth/evm-runtime-visualizer) with Gemini 3 Pro.

## Storage vs Memory vs Calldata

```
function sumArray(uint[] memory array) public pure returns (uint) {
    uint sum = 0;
    for (uint i = 0; i < array.length; i++) {
        sum += array[i];
    }
    return sum;
}
```

memory in the function params indicate variable array is a temporary variable only exists during function execution. It won't store in the storage, but it might be changed later in the function.

Calldata is used for function arguments that are passed in from an external caller, such as a user or another smart contract. Calldata is read-only, meaning that it cannot be modified by the function.

```
function isOwner(address ownerAddress) public view returns (bool) {
    return ownerAddress == msg.sender;
}
```

ownerAddress is defined in calldata, and it will be loaded in calldata, and read-only. therefore, gas cost is lowest.

The function only needs to read the value of `ownerAddress` to compare it to the `msg.sender` value, so it doesnâ€™t need to be stored in memory or storage.

```
contract ColorStorage {
    mapping(address => string) private favoriteColors;
    
    function setFavoriteColor(string calldata vs memory color) public {
        favoriteColors[msg.sender] = color;
    }
    
    function getFavoriteColor(address userAddress) public view returns (string memory) {
        return favoriteColors[userAddress];
    }
}
```

Use calldata:

Deployment gas

| transaction cost | 421340 gas |
| execution cost | 341378 gas |

Set color: red gas

| transaction cost | 24854 gas |
| execution cost | 3346 gas |

Use memory:

Deployment gas

| transaction cost | 454211 gas |
| execution cost | 371809 gas |

Set color: red gas

| transaction cost | 25317 gas |
| execution cost | 3809 gas |

Slightly reduced.

```
TypeError: Data location can only be specified for array, struct or mapping types, but "calldata" was given.
 --> test.sol:8:31:
  |
8 |     function getFavoriteColor(address calldata userAddress) public view returns (string memory) {
  |           
```

Only specify data location for complex data types.

In summary, `memory` is used for temporary variables that are only needed during the execution of a function, `calldata` is used for function arguments that are passed in from an external caller and cannot be modified, and `storage` is used to permanently store data on the blockchain that can be accessed and modified by any function within the contract.
<!-- DAILY_CHECKIN_2025-11-27_END -->

# 2025-11-26
<!-- DAILY_CHECKIN_2025-11-26_START -->










Qwen API + SDK installed.

Starting with Qwen3, the models are named using the scheme `Qwen3[-size][-type][-date]`:

-   `size`: the notation of the structure and the parameter counts. Dense models use the total saved parameters, e.g., `4B` and `32B`, while MoE models use the total saved parameters and the activated parameters for each token with a prepended `A`, e.g., `30B-A3B` and `235B-A22B`.
    
-   `type`: there are currently 4 types:
    
    -   `-Instruct`: the instruction following models that follow the predefined chat template, used for conducting tasks in conversations, downstream fine-tuning, etc.
        
    -   `-Thinking`: the thinking models that follow the predefined chat template and use chain-of-thoughts (CoT) to think deeply about the questions, used for solving complex problems.
        
    -   `-Base`: the pre-trained models that do not know the predefined chat template, used for in-context learning, downstream fine-tuning, etc.
        
    -   No type: the models with hybrid thinking modes.
        
-   `date`: the released date in yearmonth format, e.g., `2507`.
    

## **Tokens & Tokenization**

token ä»£è¡¨æ¨¡å‹å¤„ç†å’Œç”Ÿæˆçš„åŸºæœ¬å•ä½ã€‚å®ƒä»¬å¯ä»¥è¡¨ç¤ºäººç±»è¯­è¨€ä¸­çš„æ–‡æœ¬ï¼ˆå¸¸è§„ tokenï¼‰ï¼Œæˆ–è€…è¡¨ç¤ºç‰¹å®šåŠŸèƒ½ï¼Œå¦‚ç¼–ç¨‹è¯­è¨€ä¸­çš„å…³é”®å­—ï¼ˆæ§åˆ¶ token [\[1\]](https://qwen.readthedocs.io/zh-cn/latest/getting_started/concepts.html#special)ï¼‰ã€‚é€šå¸¸ï¼Œä½¿ç”¨ tokenizer å°†æ–‡æœ¬åˆ†å‰²æˆå¸¸è§„ token ï¼Œè¿™äº› token å¯ä»¥æ˜¯å•è¯ã€å­è¯æˆ–å­—ç¬¦ï¼Œå…·ä½“å–å†³äºæ‰€é‡‡ç”¨çš„ç‰¹å®š tokenization æ–¹æ¡ˆï¼Œå¹¶æŒ‰éœ€ä¸º token åºåˆ—æ·»åŠ æ§åˆ¶ token ã€‚è¯è¡¨å¤§å°ï¼Œå³æ¨¡å‹è¯†åˆ«çš„å”¯ä¸€ token æ€»æ•°ï¼Œå¯¹æ¨¡å‹çš„æ€§èƒ½å’Œå¤šåŠŸèƒ½æ€§æœ‰é‡å¤§å½±å“ã€‚å¤§å‹è¯­è¨€æ¨¡å‹é€šå¸¸ä½¿ç”¨å¤æ‚çš„ tokenization æ¥å¤„ç†äººç±»è¯­è¨€çš„å¹¿é˜”å¤šæ ·æ€§ï¼ŒåŒæ—¶ä¿æŒè¯è¡¨å¤§å°å¯æ§ã€‚Qwen è¯è¡¨ç›¸å¯¹è¾ƒå¤§ï¼Œæœ‰ 15 1646 ä¸ª tokenã€‚

å·¥ä½œåŸç†ï¼šç”¨ gemini canvas åšäº†ä¸ªäº¤äº’å¼åŠ¨ç”»ï¼ŒçœŸçš„å¾ˆèµ

![image.png](https://raw.githubusercontent.com/IntensiveCoLearning/Universal-AI/main/assets/brucexu-eth/images/2025-11-25-1764104561324-image.png)

LLM çš„èƒŒåæ˜¯ä¸€å±‚å±‚ Transformer é‡Œå‘é‡è®¡ç®—ï¼Œæ‰€ä»¥ç¬¬ä¸€æ­¥éœ€è¦å°†æ–‡æœ¬è½¬æ¢æˆå¯¹åº”çš„ token idã€‚æœ‰çš„ token å¯èƒ½æ˜¯ä¸€ä¸ªå•è¯æˆ–è€…æ–‡å­—ï¼Œæœ‰çš„å¯èƒ½æ˜¯ä¸¤ä¸ªï¼Œä¹Ÿå¯èƒ½æ˜¯ä¸€ä¸ªé•¿å•è¯åˆ‡å‰²æˆä¸åŒçš„ã€‚æ‰€ä»¥è®¡ç®—éå¸¸ç®€å•ï¼Œ1K Token ä¸Šä¸‹æ–‡ï¼Œå°±æ˜¯ 1-2K çš„å­—ç¬¦æˆ–è€… wordsï¼Œç„¶åå¯ä»¥æ¢ç®—æˆå…·ä½“çš„æ–‡ç« å’Œè¾“å…¥çš„æ–‡æœ¬æ•°é‡ã€‚

é‚£ä¹ˆ 200K token çš„ context å°±çº¦ç­‰äºï¼š

**~1 æœ¬é•¿ç¯‡å°è¯´** 200k Token å¤§çº¦ç­‰äº 25-30 ä¸‡æ±‰å­—ã€‚ç›¸å½“äºæŠŠã€Šä¸‰ä½“ã€‹ç¬¬ä¸€éƒ¨è¾“å…¥è¿›å»è¿˜æœ‰å¯Œä½™ã€‚

**150+ é¡µ PDF æ–‡æ¡£** å¯ä»¥ä¸€æ¬¡æ€§è¯»å®Œå‡ ä»½å¤æ‚çš„è´¢æŠ¥ã€æ³•å¾‹åˆåŒæˆ–å­¦æœ¯è®ºæ–‡ï¼Œå¹¶è¿›è¡Œè·¨æ–‡æ¡£åˆ†æã€‚

**10h ä¼šè®®å½•éŸ³è½¬å½•** å³ä½¿æ˜¯é•¿è¾¾æ•°å°æ—¶çš„ä¼šè®®è®°å½•ï¼Œæ¨¡å‹ä¹Ÿèƒ½ä»å¤´è¯»åˆ°å°¾ï¼Œæ€»ç»“å…¨ç¨‹ç»†èŠ‚ã€‚

**è¯è¡¨å¤§å° (Vocabulary Size) çš„æ„ä¹‰**

ä½ æåˆ°çš„ **Qwen æœ‰ 151,646 ä¸ª Token**ï¼Œè¿™å°±æ˜¯å®ƒçš„è¯è¡¨å¤§å°ã€‚ä½ å¯ä»¥æŠŠå®ƒæƒ³è±¡æˆæ¨¡å‹éšèº«æºå¸¦çš„â€œæ–°åå­—å…¸â€ã€‚

-   **è¯è¡¨å¤§**æ„å‘³ç€æ¨¡å‹è®¤è¯†æ›´å¤šçš„â€œæ•´è¯â€ã€‚æ¯”å¦‚â€œäººå·¥æ™ºèƒ½â€ï¼Œå¤§è¯è¡¨å¯èƒ½æŠŠå®ƒä½œä¸ºä¸€ä¸ª ID (Token)ï¼›å°è¯è¡¨å¯èƒ½è¦æŠŠå®ƒæ‹†æˆâ€œäººå·¥â€+â€œæ™ºèƒ½â€ (2ä¸ª Token)ã€‚
    
-   **æ•ˆç‡é«˜**è¯è¡¨è¶Šå¤§ï¼Œè¡¨ç¤ºåŒæ ·ä¸€æ®µè¯æ‰€éœ€çš„ Token æ•°é‡è¶Šå°‘ã€‚è¿™å¯¹ä¸­æ–‡å°¤å…¶é‡è¦ï¼ˆå› ä¸ºå¾ˆå¤šè‹±æ–‡æ¨¡å‹è¯è¡¨å¯¹ä¸­æ–‡æ”¯æŒä¸å¥½ï¼Œå¯¼è‡´ä¸­æ–‡è¢«æ‹†å¾—ç¨€ç¢ï¼Œç‰¹åˆ«è´¹é’±è´¹ç®—åŠ›ï¼‰ã€‚
    
-   **ä»£ä»·**è¯è¡¨ä¹Ÿä¸æ˜¯è¶Šå¤§è¶Šå¥½ã€‚è¯è¡¨è¶Šå¤§ï¼Œæ¨¡å‹é¢„æµ‹ä¸‹ä¸€ä¸ª Token æ—¶ï¼Œéœ€è¦ä»æ›´å¤šé€‰é¡¹ä¸­åšé€‰æ‹©ï¼ˆè®¡ç®—é‡å˜å¤§ï¼‰ï¼Œä¸”æ¨¡å‹çš„â€œåµŒå…¥å±‚â€å‚æ•°é‡ä¼šæ˜¾è‘—å¢åŠ ã€‚
    

## Token æ•°é‡ vs. KB / MB æ–‡ä»¶å¤§å°

å®¹æ˜“æ··æ·†çš„ç‚¹ï¼š

1.  **token æ•°é‡**
    
    -   æ˜¯â€œæ¨¡å‹è§†è§’â€çš„é•¿åº¦ã€‚
        
    -   éœ€è¦å…ˆè¿‡ä¸€é tokenizerï¼Œç®—â€œåˆ‡å‡ºæ¥å¤šå°‘å— tokenâ€ã€‚
        
2.  **æ–‡ä»¶å¤§å°ï¼ˆKB / MBï¼‰**
    
    -   æ˜¯â€œå­˜å‚¨è§†è§’â€çš„é•¿åº¦ã€‚
        
    -   è·Ÿç¼–ç æ–¹å¼ï¼ˆUTF-8/UTF-16ï¼‰ã€ç©ºæ ¼ã€æ¢è¡Œã€å›¾ç‰‡ã€å‹ç¼©ç­‰éƒ½æœ‰å…³ã€‚
        

åŒä¸€ä¸ª 1MB çš„ PDF æ–‡ä»¶ï¼š

-   å¦‚æœå¤§é‡æ˜¯è‹±æ–‡ + å¾ˆå¤šç©ºæ ¼ï¼Œtoken å¯èƒ½ç›¸å¯¹å°‘ã€‚
    
-   å¦‚æœæ˜¯é«˜å¯†åº¦ä¸­æ–‡æˆ–ä»£ç ï¼Œtoken å¯èƒ½å¾ˆå¤šã€‚
    

æ‰€ä»¥ï¼š

> ä¸èƒ½ç®€å•ç”¨â€œæ–‡ä»¶å¤šå°‘ MBâ€æ¨æ–­èƒ½ä¸èƒ½å¡è¿› 200k ä¸Šä¸‹æ–‡ï¼›  
> æ›´å‡†ç¡®çš„åšæ³•æ˜¯ç”¨å¯¹åº” tokenizer å®é™…æ•°ä¸€é token æ•°é‡ã€‚

### å¦‚ä½•ä¼°ç®— token å’Œå†…å®¹é•¿åº¦

-   ä¸åŒæ¨¡å‹ / tokenizer ä¸‹ï¼Œ**1 token â‰  å›ºå®šå­—æ•°**ï¼š
    
    -   è‹±æ–‡é‡Œå¸¸ç”¨ä¼°ç®—ï¼š1 token â‰ˆ 0.75 ä¸ªè‹±æ–‡å•è¯ã€‚
        
    -   ä¸­æ–‡é‡Œï¼Œå¾ˆå¤š tokenizer ä¼šæŠŠä¸€ä¸ªæ±‰å­—æˆ–å¸¸ç”¨è¯å½“ä½œ 1 ä¸ª tokenï¼Œä½†æœ‰æ—¶ä¼šå¤šä¸€ç‚¹æˆ–å°‘ä¸€ç‚¹ã€‚
        
-   200k æ˜¯**æ€»ä¸Šä¸‹æ–‡**ï¼šåŒ…æ‹¬ system promptã€ä½ æ‰€æœ‰å†å²å¯¹è¯ã€æ–‡ä»¶å†…å®¹ï¼Œä»¥åŠæ¨¡å‹è¾“å‡ºæœ¬èº«ã€‚
    

### éœ€è¦è­¦æƒ•çš„ä¸€ç‚¹ï¼šæœ‰æ•ˆè®°å¿† vs æ ‡ç§° context

ç°åœ¨å¾ˆå¤šæ–‡ç« å’Œ benchmark éƒ½åœ¨è®¨è®ºï¼š  
è™½ç„¶æ ‡ç§° 200kã€1Mï¼Œä½†åœ¨**è¶…è¿‡ 50â€“80k å·¦å³**æ—¶ï¼Œæ¨¡å‹å¯¹è¿œç«¯ä¿¡æ¯çš„å‡†ç¡®æ£€ç´¢ä¼šæ˜æ˜¾å˜å·®ï¼Œå°¤å…¶æ˜¯å¤æ‚æ¨ç†ä»»åŠ¡ã€‚[Stefano Demiliani+1](https://demiliani.com/2025/11/02/understanding-llm-performance-degradation-a-deep-dive-into-context-window-limits/?utm_source=chatgpt.com)

æ‰€ä»¥ï¼Œå®æˆ˜é‡Œä½ å¯ä»¥ç†è§£ä¸ºï¼š

> 200k æ˜¯â€œæœ€å¤§å·¥ä½œè®°å¿†ç©ºé—´â€ï¼Œ  
> çœŸæ­£åœ¨é‡Œé¢åšé«˜ç²¾åº¦æŸ¥æ‰¾/æ¨ç†æ—¶ï¼Œ**æœ‰æ•ˆå¸¦å®½å¾€å¾€ä½äºè¿™ä¸ªä¸Šé™**ï¼Œè¦é…åˆåˆ†å—ã€ç´¢å¼•ã€RAG ç­‰æ‰‹æ®µã€‚

TODO [https://qwen.readthedocs.io/zh-cn/latest/index.html](https://qwen.readthedocs.io/zh-cn/latest/index.html) æ¨¡å‹çš„åŠŸèƒ½æ•´ä¸ªæœ¬åœ°è·‘ä¸€éï¼Œå¦‚æœæ¶‰åŠåˆ°å¾®è°ƒç­‰ï¼Œä½¿ç”¨ä½å¤æ‚åº¦å¼€æºæ¨¡å‹
<!-- DAILY_CHECKIN_2025-11-26_END -->

# 2025-11-25
<!-- DAILY_CHECKIN_2025-11-25_START -->











[https://www.zetachain.com/docs/developers/tutorials/hello/](https://www.zetachain.com/docs/developers/tutorials/hello/)

![image.png](https://raw.githubusercontent.com/IntensiveCoLearning/Universal-AI/main/assets/brucexu-eth/images/2025-11-25-1764033488074-image.png)

åˆå§‹åŒ– example ä¹‹åï¼Œè¿™ä¸ª onCall æ–¹æ³•å°±æ˜¯ç”¨äºåšè·¨é“¾ä½¿ç”¨çš„ã€‚é€šè¿‡å‘é€æ¶ˆæ¯ï¼Œç„¶åé€šçŸ¥å…¶ä»–çš„é“¾æ¥ä¸Šçš„é“¾è¿›è¡Œæ“ä½œã€‚

```
forge create Universal --rpc-url https://zetachain-athens-evm.blockpi.network/v1/rpc/public --private-key $PKK --broadcast
[â Š] Compiling...
No files changed, compilation skipped
Deployer: 0xD41dC0b5c27c8554D5fb0495279151d4E5500e3B
Deployed to: 0x3392828C9D464D2222F5b6F720B6Ca2772685940
Transaction hash: 0xfbafa81ee69fd294714a73e6b0bf65b1c1a0a225132a9812c2dd6a2c07ffd997
```

My First ZetaChain TX.

æµ‹è¯•å¸æ°´é¾™å¤´ [https://www.zetachain.com/docs/reference/faucet/](https://www.zetachain.com/docs/reference/faucet/)

84532 â”‚ base\_sepolia

```
zetachain evm call --receiver 0x3392828C9D464D2222F5b6F720B6Ca2772685940 --chain-id 84532 --types string --values alice --private-key $PKK

From:   0xD41dC0b5c27c8554D5fb0495279151d4E5500e3B
To:     0x3392828C9D464D2222F5b6F720B6Ca2772685940 on ZetaChain
Call on revert: false

Contract call details:
Function parameters: alice
Parameter types: ["string"]

? Proceed with the transaction? yes
Transaction hash: 0xe8427df51c87cfba654dbc05937e5b445a3c5ea528f9285ffbb5041651683a6a
```

å…·ä½“çš„äº¤æ˜“ params on baseï¼Œsent to zetachain gateway on base, includes params, payload, etc.

```
Function: call(address, bytes, (address,bool,address,bytes,uint256))
#	Name	Type	Data
1	receiver	address
0x3392828C9D464D2222F5b6F720B6Ca2772685940
2	payload	bytes
0x00000000000000000000000000000000000000000000000000000000000000200000000000000000000000000000000000000000000000000000000000000005616c696365000000000000000000000000000000000000000000000000000000
2	revertOptions.revertAddress	address
0xD41dC0b5c27c8554D5fb0495279151d4E5500e3B
2	revertOptions.callOnRevert	bool
false
2	revertOptions.abortAddress	address
0x0000000000000000000000000000000000000000
2	revertOptions.revertMessage	bytes
0x
2	revertOptions.onRevertGasLimit	uint256
200000
```

[https://testnet.zetascan.com/tx/0x24450579034209dddbd436c15ad54c5634d0a1b30a5d0cb89c985d07f3d06a03](https://testnet.zetascan.com/tx/0x24450579034209dddbd436c15ad54c5634d0a1b30a5d0cb89c985d07f3d06a03)

TODO bytes èƒ½å­˜å¤šå°‘æ•°æ®ï¼Ÿå¦‚æœæ˜¯ä¸€ä¸ªå¾ˆå¤æ‚çš„è·¨é“¾åˆçº¦è°ƒç”¨ï¼Œå¦‚ä½•ä¼ é€’å‚æ•°å‘¢ï¼Ÿ

```
zetachain q cctx --hash 0xe8427df51c87cfba654dbc05937e5b445a3c5ea528f9285ffbb5041651683a6a
84532 â†’ 7001 âœ… OutboundMined
CCTX:     0xb1438fb6c86ddbc325fbd99266e63431906e5f55c60ad4b97cd4a7865d1b6402
Tx Hash:  0xe8427df51c87cfba654dbc05937e5b445a3c5ea528f9285ffbb5041651683a6a (on chain 84532)
Tx Hash:  0x24450579034209dddbd436c15ad54c5634d0a1b30a5d0cb89c985d07f3d06a03 (on chain 7001)
Sender:   0xD41dC0b5c27c8554D5fb0495279151d4E5500e3B
Receiver: 0x3392828C9D464D2222F5b6F720B6Ca2772685940
Message:  00000000000000000000000000000000000000000000000000000000000000200000000000000000000000000000000000000000000000000000000000000005616c696365000000000000000000000000000000000000000000000000000000
```

[https://sepolia.basescan.org/tx/0xe8427df51c87cfba654dbc05937e5b445a3c5ea528f9285ffbb5041651683a6a](https://sepolia.basescan.org/tx/0xe8427df51c87cfba654dbc05937e5b445a3c5ea528f9285ffbb5041651683a6a)

zetachain q cctx --help

Usage: zetachain query cctx \[options\]

Queries the real-time status of a cross-chain transaction by its inbound transaction hash. You can control

polling frequency, timeout, and target RPC endpoint.

å¤§æ¦‚å·¥ä½œæµç¨‹ï¼š

1.  åœ¨ base å‘é€äº†ä¸€ä¸ª call åŒ…æ‹¬è°ƒç”¨çš„è·¨é“¾åˆçº¦ã€methodã€å‚æ•°ç­‰åˆ° zetachain çš„ base gateway
    
2.  é“¾ä¸‹çš„ä»£ç ç›‘å¬äº‹ä»¶ï¼Œç„¶åæ“ä½œ zetachain çš„åœ°å€ **0x735b14BB79463307AAcBED86DAf3322B1e6226aB** æ¥åœ¨ zetachain ä¸Šé¢é‡æ”¾è¯·æ±‚ï¼ŒåŒ…æ‹¬åœ°å€å’Œ message
    
3.  ä¹‹åå°±è°ƒç”¨äº†åˆçº¦çš„å¯¹åº”æ–¹æ³•ï¼Œå¹¶ä¸”åœ¨ zetachain çš„åˆçº¦æ‰“å°äº† event æ¶ˆæ¯
    

è¿™æ ·å®ç°äº†è·¨é“¾åŠŸèƒ½ã€‚

TODO ZetaChain çš„ 0x6c533f7fE93fAE114d0954697069Df33C9B74fD7 GatewayZEVM è´Ÿè´£é‡æ”¾è¯·æ±‚ï¼Œä»£ç å®ç°æ˜¯æ€ä¹ˆæ ·çš„ï¼Ÿäº†è§£ä¸€ä¸‹ [https://testnet.zetascan.com/tx/0x24450579034209dddbd436c15ad54c5634d0a1b30a5d0cb89c985d07f3d06a03](https://testnet.zetascan.com/tx/0x24450579034209dddbd436c15ad54c5634d0a1b30a5d0cb89c985d07f3d06a03) [https://testnet.zetascan.com/address/0xe91D93D4eFd6347bD9fA5fdb5B24394CFB22a6Df?tab=contract](https://testnet.zetascan.com/address/0xe91D93D4eFd6347bD9fA5fdb5B24394CFB22a6Df?tab=contract)

TODO çœ‹èµ·æ¥ ZetaChain æ”¯ä»˜äº†è·¨é“¾æ¶ˆæ¯çš„ gasï¼Œåœ¨ç»æµæ€§ä¸Šå¦‚ä½•å½¢æˆé—­ç¯ï¼Ÿè¶Šå¤šè·¨é“¾è¯·æ±‚ï¼Œä¼¼ä¹æ˜¯è¶Šå¤š gas æ¶ˆè€—ï¼Œè€Œä¸”æ˜¯å„ä¸ªé“¾çš„ã€‚

TODO UniversalContract çš„åˆçº¦ä»£ç åŒ…æ‹¬ä»€ä¹ˆï¼Ÿå…·ä½“å®ç°ä»€ä¹ˆåŠŸèƒ½ï¼Ÿimport "@zetachain/protocol-contracts/contracts/zevm/interfaces/UniversalContract.sol";

A universal contract must implement the `onCall` function. This function is triggered when the contract receives a call from a connected chain via the Gateway. The function processes incoming data, which includes:

-   `context`: A `MessageContext` struct containing:
    
    -   `chainID`: The chain ID of the connected chain that initiated the cross-chain call.
        
    -   `sender`: The address (EOA or contract) that called the Gateway on the connected chain.
        
    -   `origin`: Deprecated.
        
-   `zrc20`: The address of the ZRC-20 token representing assets from the source chain.
    
-   `amount`: The amount of tokens transferred.
    
-   `message`: The encoded payload data.
    

In this example, `onCall` decodes the message into a string and emits an event.

`onCall` should only be called by the Gateway to ensure that it is only called as a response to a call on a connected chain and that you can trust the values of the function parameters. This is enforced by the `onlyGateway` modifier, which is inherited from `UniversalContract`.

* * *

[https://getfoundry.sh/guides/project-setup/soldeer/](https://getfoundry.sh/guides/project-setup/soldeer/)

Foundry has been using git submodules to handle dependencies up until now.

A new approach has been in the making, [soldeer.xyz](http://soldeer.xyz), which is a Solidity native dependency manager built in Rust and open sourced (check the repository [https://github.com/mario-eth/soldeer](https://github.com/mario-eth/soldeer)).

```
forge soldeer install @openzeppelin-contracts~5.0.2
```

This will download the dependency from the central repository and install it into a `dependencies` directory.

Soldeer can manage two types of dependency configuration: using `soldeer.toml` or embedded in the `foundry.toml`. In order to work with Foundry, you have to define the `[dependencies]` config in the `foundry.toml`. This will tell the `soldeer CLI` to define the installed dependencies there. E.g.

```
# Full reference https://github.com/foundry-rs/foundry/tree/master/crates/config [profile.default]auto_detect_solc = falsebytecode_hash = "none"fuzz = { runs = 1_000 }libs = ["dependencies"] # <= This is important to be addedgas_reports = ["*"] [dependencies] # <= Dependencies will be added under this config"@openzeppelin-contracts" = { version = "5.0.2" }"@uniswap-universal-router" = { version = "1.6.0" }"@prb-math" = { version = "4.0.2" }forge-std = { version = "1.8.1" }
```

* * *

Solidity Bytes

`bytes` æœ¬èº«æ˜¯ã€Œå¯å˜é•¿åº¦å­—èŠ‚æ•°ç»„ã€ï¼Œç†è®ºä¸Šæ²¡æœ‰ Solidity çº§åˆ«çš„å›ºå®šä¸Šé™ï¼Œé•¿åº¦ç”¨ `uint256` å­˜ï¼Œæ‰€ä»¥ä¸Šé™æ˜¯ `2^256-1` ä¸ªå­—èŠ‚ï¼Œä½†åœ¨ç°å®é‡Œè¿œè¿œè¾¾ä¸åˆ°ï¼ŒçœŸæ­£é™åˆ¶æ˜¯ gas å’ŒåŒºå— gas limitã€‚

### å›ºå®šé•¿åº¦ï¼š`bytes1` ~ `bytes32`

-   ç¼–è¯‘æœŸé•¿åº¦å›ºå®šï¼Œä¸èƒ½å˜ã€‚
    
-   å ç”¨çš„ storage ç©ºé—´ = å¯¹åº”å­—èŠ‚æ•°ï¼ˆæ”¾åœ¨ 32 å­—èŠ‚ slot é‡Œï¼‰ã€‚
    

å…³äº bit bytes ä¹‹ç±»çš„çŸ¥è¯† [https://x.com/brucexu\_eth/status/1902631404862881952](https://x.com/brucexu_eth/status/1902631404862881952)

### å•ä¸ª `bytes` çŠ¶æ€å˜é‡åœ¨ storage ä¸­çš„å¸ƒå±€ï¼ˆç®€å•ç†è§£ç‰ˆï¼‰

åªéœ€è¦è®°ä½ï¼š

-   å¦‚æœé•¿åº¦ â‰¤ 31 å­—èŠ‚ï¼š
    
    -   æ•´ä¸ª `bytes`ï¼ˆæ•°æ® + é•¿åº¦ï¼‰ä¼šå¡åœ¨åŒä¸€ä¸ª 32 å­—èŠ‚çš„ storage slot ä¸­ã€‚
        
-   å¦‚æœé•¿åº¦ > 31 å­—èŠ‚ï¼š
    
    -   slot é‡Œå­˜çš„æ˜¯ã€Œé•¿åº¦ + æ•°æ®èµ·å§‹ä½ç½®æ ‡è®°ã€ï¼ŒçœŸæ­£çš„æ•°æ®æ‹†å¼€æ”¾åœ¨åç»­è‹¥å¹² slotï¼ˆä» `keccak256(slot)` å¼€å§‹ï¼‰ã€‚
        

è¿™æ„å‘³ç€ï¼š

-   å° `bytes`ï¼ˆä¾‹å¦‚ 20 å­—èŠ‚åœ°å€ã€32 å­—èŠ‚å“ˆå¸Œç­‰ï¼‰å­˜å‚¨å¾ˆçœç©ºé—´ã€‚
    
-   é•¿ `bytes` ä¼šåˆ†å¸ƒåœ¨å¾ˆå¤š slotï¼Œä¸Šä¸‹é“¾å’Œä¿®æ”¹éƒ½ä¼šæ›´è´µã€‚
    

* * *

How to decode AIB-encoded string like:

```
00000000000000000000000000000000000000000000000000000000000000200000000000000000000000000000000000000000000000000000000000000005616c696365000000000000000000000000000000000000000000000000000000
```

### 1\. Break the string into 32-byte words

The decoded message hidden in that EVM bytecode is the string: **"alice"**.

This is a standard **ABI-encoded string**. The Ethereum Virtual Machine (EVM) processes data in 32-byte "words" (which represent 64 hexadecimal characters).

Here is the step-by-step breakdown of how to decode it.

* * *

### 1\. Break the string into 32-byte words

To make sense of the data, we split the long string into chunks of 64 characters (32 bytes) each.

**Word 1 (The Offset):** `0000000000000000000000000000000000000000000000000000000000000020`

-   **Value:** Hex `0x20` = Decimal `32`.
    
-   **Meaning:** This tells the EVM that the actual data for this dynamic type (string) starts **32 bytes** after the beginning of this slot. Since one word is 32 bytes, it points to the very next line.
    

**Word 2 (The Length):** `0000000000000000000000000000000000000000000000000000000000000005`

-   **Value:** Hex `0x05` = Decimal `5`.
    
-   **Meaning:** This indicates the length of the string is **5 characters**.
    

**Word 3 (The Content):** `616c69636500000000000000000000000000000000000000000000000000000`

-   **Value:** `616c696365...`
    
-   **Meaning:** This is the actual text data, encoded in Hexadecimal (ASCII/UTF-8). Strings are left-aligned in EVM storage, so the data is at the start, and the rest is "padding" (zeros).
    

è¿™é‡Œçš„æ•°å­—éƒ½æ˜¯ hex 16 è¿›åˆ¶ï¼Œæ‰€ä»¥ 64 ä½å­˜å‚¨ç©ºé—´æ˜¯ 32 bytesï¼Œ1 bytes = 8 bits = 2 hex å­˜å‚¨ç©ºé—´ã€‚
<!-- DAILY_CHECKIN_2025-11-25_END -->

# 2025-11-24
<!-- DAILY_CHECKIN_2025-11-24_START -->












ä»Šå¤©å¼€å§‹å­¦ä¹ äº†ï¼Œå…ˆæ‰“ä¸ªå¡æµ‹è¯•ä¸€ä¸‹åŠŸèƒ½ã€‚
<!-- DAILY_CHECKIN_2025-11-24_END -->
<!-- Content_END -->
